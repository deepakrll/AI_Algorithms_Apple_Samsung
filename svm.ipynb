#3. SVR
# Import necessary libraries
from sklearn.svm import SVR
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd

# Load the dataset from Google Drive
file_path = '/content/drive/My Drive/Colab Notebooks/iphone_samsung_sales_with_models.csv'
df = pd.read_csv(file_path)

# Display the first few rows
print("First few rows of the dataset:\n", df.head())

# Encode categorical variables
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['Brand'] = le.fit_transform(df['Brand'])  # iPhone=0, Samsung=1
df['Model'] = le.fit_transform(df['Model'])  # Assign numeric labels to models

# Define features and target variable
X = df[['Brand', 'Model', 'Sales Units']]  # Features
y = df['Revenue (INR)']  # Target

# Split the dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the Support Vector Regressor
svm_reg = SVR(kernel='rbf')  # Radial Basis Function kernel for non-linear relationships
svm_reg.fit(X_train, y_train)

# Make predictions on the test set
y_pred_svm = svm_reg.predict(X_test)

# Evaluate the model
mse_svm = mean_squared_error(y_test, y_pred_svm)
r2_svm = r2_score(y_test, y_pred_svm)

print("\n--- SVM Regression Evaluation ---")
print(f"Mean Squared Error (MSE): {mse_svm:.2f}")
print(f"R² Score: {r2_svm:.2f}")

# Interpretation
print("\n--- Interpretation ---")
print(f"The Mean Squared Error of {mse_svm:.2f} indicates the average squared difference between actual and predicted revenues.")
print(f"The R² score of {r2_svm:.2f} means that {r2_svm*100:.2f}% of the variability in revenue is explained by the model.")
print("SVM with RBF kernel can capture complex, non-linear relationships in the data.")
